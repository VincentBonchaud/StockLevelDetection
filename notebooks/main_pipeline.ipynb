{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rN6-6JavTmyM"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "217YoDxMTmyV"
   },
   "source": [
    "# Global variables definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = Path.cwd().parent\n",
    "CSV_LINK = '...' # I'm not authorized to display the url publicly\n",
    "CSV_NAME = 'dataset.csv'\n",
    "AUGMENTED_CSV_NAME = 'augmented_data.csv'\n",
    "\n",
    "CSV_PATH = ROOT_DIR / CSV_NAME\n",
    "BASE_IMG_DIR = ROOT_DIR / 'img'\n",
    "\n",
    "WITH_IMGAUG_DATA_AUG = False\n",
    "WITH_OPENCV_DATA_AUG = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moYHlo-WTmyY"
   },
   "source": [
    "# Download the csv metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable unverified HTTPS warnings\n",
    "import urllib3\n",
    "urllib3.disable_warnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CSV_PATH.is_file():\n",
    "    raw_csv = requests.get(CSV_LINK, verify=False).content\n",
    "    CSV_PATH.write_bytes(raw_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLzlE_lxTmya"
   },
   "source": [
    "# Download the images with inventory level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_base_images(csv_path, output_dir):\n",
    "    prefix_url = '...' # I'm not authorized to display the url publicly\n",
    "    \n",
    "    df = pd.read_csv(csv_path, sep=';', index_col=0).dropna()\n",
    "    \n",
    "    for (label_id, inv_level, img_url) in df.itertuples():\n",
    "        full_url = prefix_url + img_url\n",
    "        output_file = output_dir / f'{label_id}_{inv_level}.png'\n",
    "        \n",
    "        img_data = requests.get(full_url, verify=False).content\n",
    "        output_file.write_bytes(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not BASE_IMG_DIR.is_dir():\n",
    "    BASE_IMG_DIR.mkdir()\n",
    "    download_base_images(CSV_PATH, BASE_IMG_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYqg7qOGTmyd"
   },
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_files = list(BASE_IMG_DIR.glob('*'))\n",
    "len(dataset_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files, test_files = train_test_split(dataset_files, test_size=0.2, random_state=42)\n",
    "len(train_files), len(test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlxDMOAHTmyf"
   },
   "source": [
    "# Load training files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the gray image and normalize it\n",
    "\n",
    "def pad_resize(img, h, w):\n",
    "    ratio_h = h / img.shape[0]\n",
    "    ratio_w = w / img.shape[1]\n",
    "    \n",
    "    # Resize while keeping same ratio\n",
    "    ratio = min(ratio_h, ratio_w)\n",
    "    img = cv2.resize(img, (0, 0), fx=ratio, fy=ratio, interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # Pad the rest of the image\n",
    "    pad_y, pad_x = h - img.shape[0], w - img.shape[1]\n",
    "    img = cv2.copyMakeBorder(\n",
    "        img,\n",
    "        top = pad_y // 2,\n",
    "        bottom = (pad_y + 1) // 2,\n",
    "        left = pad_x // 2,\n",
    "        right = (pad_x + 1) // 2,\n",
    "        borderType = cv2.BORDER_CONSTANT,\n",
    "        value = [255, 255, 255]\n",
    "    )\n",
    "    \n",
    "    return img\n",
    "\n",
    "def load_gray(file_paths, reshape_h, reshape_w):\n",
    "    # Load the gray images & normalize\n",
    "    imgs = [cv2.imread(str(f), cv2.IMREAD_GRAYSCALE).astype(np.float32) for f in file_paths]\n",
    "    \n",
    "    # Resize the images\n",
    "    imgs = np.asarray([pad_resize(img, reshape_h, reshape_w) for img in imgs])\n",
    "    \n",
    "    imgs = imgs[..., None] / 255\n",
    "\n",
    "    return imgs\n",
    "\n",
    "reshape_h, reshape_w = 224, 224\n",
    "train_imgs = load_gray(train_files, reshape_h, reshape_w)\n",
    "test_imgs = load_gray(test_files, reshape_h, reshape_w)\n",
    "\n",
    "plt.imshow(train_imgs[0,:,:,0], cmap='gray'); plt.show()\n",
    "plt.imshow(train_imgs[-1,:,:,0], cmap='gray'); plt.show()\n",
    "\n",
    "train_imgs.shape, test_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the inventory level from the filenames\n",
    "\n",
    "def extract_inv_level(file_paths):\n",
    "    # Remove file extension & Keep only the inventory level\n",
    "    levels_str = [f.stem.split('_')[-1] for f in file_paths]\n",
    "    \n",
    "    # Convert to float\n",
    "    return np.array(levels_str, dtype=np.float32)\n",
    "\n",
    "train_y, test_y = extract_inv_level(train_files), extract_inv_level(test_files)\n",
    "train_y[:5], test_y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "import math\n",
    "import random\n",
    "from skimage import io, filters, segmentation\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, max_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files\n",
    "gt = extract_inv_level(dataset_files)\n",
    "orig_imgs = []\n",
    "gray_imgs = []\n",
    "for file in dataset_files:\n",
    "    orig_img = skimage.io.imread(file)\n",
    "    orig_imgs.append(orig_img)\n",
    "    gray_img = skimage.color.rgb2gray(orig_img)\n",
    "    gray_img *= 255\n",
    "    gray_img.astype(np.uint8)\n",
    "    gray_imgs.append(gray_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(orig_imgs, gray_imgs, gt, imno, pred=None):\n",
    "    title = f'{imno}Ground truth: {gt[imno]:.2f}'\n",
    "\n",
    "    if pred:\n",
    "        title = f'{imno}Ground truth: {gt[imno]:.2f} | Pred: {pred:.2f}'\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(6, 4))\n",
    "    ax = axes.ravel()\n",
    "\n",
    "    ax[0].imshow(orig_imgs[imno])\n",
    "    ax[0].set_title(title)\n",
    "    ax[1].imshow(gray_imgs[imno], cmap=plt.cm.gray)\n",
    "    ax[1].set_title(title)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with a simple image: pens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(orig_imgs, gray_imgs, gt, 62)\n",
    "show_images(orig_imgs, gray_imgs, gt, 63)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a baseline, we can use dummy and random classifiers, or a classifier based on the average color:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_classify(img, gt=gt):\n",
    "    values, counts = np.unique(gt, return_counts=True)\n",
    "    res = gt[np.argmax(counts)]\n",
    "    return res\n",
    "\n",
    "def random_classify(img, gt=gt):\n",
    "    idx = np.random.randint(len(gt))\n",
    "    res = gt[idx]\n",
    "    return res\n",
    "\n",
    "def mean_pixels_color_classify(img, gt=None):\n",
    "    mask = (img < 255)\n",
    "    avg = np.mean(img[mask])\n",
    "    lvl = 1 - (avg / 255)\n",
    "\n",
    "    ys = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "    for y in ys:\n",
    "        if abs(y - lvl) <= 0.1:\n",
    "            res = y\n",
    "            break\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_62 = gray_imgs[62]\n",
    "im_63 = gray_imgs[63]\n",
    "print('Dummy:')\n",
    "print(\"pred: \", dummy_classify(im_62), dummy_classify(im_63))\n",
    "print(\"true: \", gt[62], gt[63])\n",
    "print('Mean color:')\n",
    "print(\"pred: \", mean_pixels_color_classify(im_62), mean_pixels_color_classify(im_63))\n",
    "print(\"true: \", gt[62], gt[63])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all_and_get_metrics(cls, gt=gt, verbose=True):\n",
    "    y_pred = [cls(gray_imgs[imno], gt) for imno in range(len(gt))]\n",
    "    if verbose:\n",
    "        print(\"MSE: \", mean_squared_error(gt, y_pred))\n",
    "        print(\"MAE: \", mean_absolute_error(gt, y_pred))\n",
    "        print(\"Max err: \", max_error(gt, y_pred))\n",
    "    t = np.sum(np.asarray(y_pred).astype(np.float32) == (gt))\n",
    "    if verbose:\n",
    "        print(f\"Accuracy: {t}/{len(gt)} {t / len(gt)}\")\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rand = predict_all_and_get_metrics(random_classify)\n",
    "y_pred_dummy = predict_all_and_get_metrics(dummy_classify)\n",
    "y_pred_mean_pixels_color = predict_all_and_get_metrics(mean_pixels_color_classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_biggest_errors(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    errors = abs(y_true - y_pred)\n",
    "    idx_biggest_errors = np.argsort(errors, axis=-1)[::-1]\n",
    "    return errors[idx_biggest_errors], idx_biggest_errors\n",
    "\n",
    "biggest_errors, idx_biggest_errors = get_biggest_errors(gt, y_pred_mean_pixels_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Largest errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    j = idx_biggest_errors[i]\n",
    "    show_images(orig_imgs, gray_imgs, gt, j, y_pred_mean_pixels_color[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smallest errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    j = idx_biggest_errors[-i-1]\n",
    "    show_images(orig_imgs, gray_imgs, gt, j, y_pred_mean_pixels_color[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with segmenting using the watershed algorithm.  \n",
    "We use a Sobel filter to get our topographic map.  \n",
    "The markers here are hard-coded, the values defined empirically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def watershed_seg(img):\n",
    "    elevation_map = skimage.filters.sobel(img)\n",
    "\n",
    "    BACKGROUND = 1\n",
    "    OBJECTS = 2\n",
    "\n",
    "    markers = np.zeros(img.shape, dtype=np.uint)\n",
    "    markers[(img > 145) & (img < 165)] = BACKGROUND # background\n",
    "    markers[img < 50] = OBJECTS # black\n",
    "    markers[img > 210] = OBJECTS # white\n",
    "\n",
    "    segmentation = skimage.segmentation.watershed(elevation_map, markers, mask=(img<255))\n",
    "    \n",
    "    return segmentation, elevation_map, markers\n",
    "\n",
    "def show_watershed_seg(orig_imgs, gray_imgs, gt, imno, segmentation, elevation_map, markers):\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(10, 6))\n",
    "    ax = axes.ravel()\n",
    "\n",
    "    title = f'{imno}Ground truth: {gt[imno]:.2f}'\n",
    "\n",
    "    ax[0].imshow(orig_imgs[imno])\n",
    "    ax[0].set_title(title)\n",
    "\n",
    "    ax[1].imshow(gray_imgs[imno], cmap=plt.cm.gray)\n",
    "    ax[2].imshow(elevation_map)\n",
    "    ax[2].set_title('Sobel')\n",
    "    ax[3].imshow(segmentation, cmap=plt.cm.nipy_spectral)\n",
    "    ax[3].set_title('Segmentation')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "imno = 63\n",
    "im_63 = gray_imgs[imno]\n",
    "\n",
    "segmentation, elevation_map, markers = watershed_seg(im_63)\n",
    "show_watershed_seg(orig_imgs, gray_imgs, gt, imno, segmentation, elevation_map, markers)\n",
    "\n",
    "imno = 43\n",
    "im_43 = gray_imgs[imno]\n",
    "\n",
    "segmentation, elevation_map, markers = watershed_seg(im_43)\n",
    "show_watershed_seg(orig_imgs, gray_imgs, gt, imno, segmentation, elevation_map, markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def watershed_hcmarkers_classify(img, gt=None):\n",
    "    segmentation, _, _ = watershed_seg(img)\n",
    "    BACKGROUND = 1\n",
    "    OBJECTS = 2\n",
    "    epsilon = 1e-6\n",
    "    \n",
    "    bg = (segmentation == BACKGROUND).sum()\n",
    "    fg = (segmentation == OBJECTS).sum()\n",
    "        \n",
    "    lvl = fg / (fg+bg+epsilon)\n",
    "    \n",
    "    ys = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "    for y in ys:\n",
    "        if abs(y - lvl) <= 0.1:\n",
    "            return y\n",
    "        \n",
    "watershed_hcmarkers_classify(gray_imgs[44]), gt[44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_watershed1 = predict_all_and_get_metrics(watershed_hcmarkers_classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biggest_errors, idx_biggest_errors = get_biggest_errors(gt, y_pred_watershed1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are not great on the whole data set. This method is too naive to generalize well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    j = idx_biggest_errors[i]\n",
    "    show_images(orig_imgs, gray_imgs, gt, j, y_pred_watershed1[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smallest errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    j = idx_biggest_errors[-i-1]\n",
    "    show_images(orig_imgs, gray_imgs, gt, j, y_pred_watershed1[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MY2c6ZZxTmyh"
   },
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.util import random_noise\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.seed(42)\n",
    "\n",
    "# Define the augmentation to apply\n",
    "aug = iaa.Sequential([\n",
    "    iaa.Fliplr(0.7), # horizontal flips\n",
    "        \n",
    "    # Small gaussian blur with random sigma between 0 and 0.5.\n",
    "    iaa.Sometimes(0.5, iaa.GaussianBlur(sigma=(0, 0.5))),\n",
    "    \n",
    "    # Strengthen or weaken the contrast in each image.\n",
    "    iaa.LinearContrast((0.75, 1.5)),\n",
    "    \n",
    "    # Make some images brighter and some darker.\n",
    "    iaa.Multiply((0.7, 1.3), per_channel=0.2),\n",
    "    \n",
    "    # Scale/zoom them, translate/move them, rotate them and shear them.\n",
    "    iaa.Affine(\n",
    "        scale={\"x\": (1, 1.1), \"y\": (1, 1.1)},\n",
    "    )\n",
    "], random_order=True) # apply augmenters in random order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _hflip(imgs, y):\n",
    "    return (np.reshape([cv2.flip(img, 1) for img in imgs], imgs.shape), y)\n",
    "\n",
    "def _noise(imgs, y):\n",
    "    return (np.reshape([random_noise(img, mode='s&p', amount=0.061) for img in imgs], imgs.shape), y)\n",
    "\n",
    "def _imgaug(imgs, y, aug_sequence, nb_aug=3):\n",
    "    augmented_images = []\n",
    "    augmented_y = []\n",
    "    \n",
    "    for i in range(len(imgs)):\n",
    "        duplicated_imgs = np.array([imgs[i] for _ in range(nb_aug)])\n",
    "        augmented_images += list(aug_sequence(images=duplicated_imgs))\n",
    "        augmented_y += [y[i]] * nb_aug\n",
    "        \n",
    "    return np.array(augmented_images), np.array(augmented_y)\n",
    "\n",
    "\n",
    "def data_augmentation(train_imgs, train_y, aug_sequence):\n",
    "    '''\n",
    "    Augment training data by applying tranformations on it.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    train_imgs:\n",
    "        A list of the training images data\n",
    "    train_y:\n",
    "        A list of the inventory level for each training image\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    aug_imgs:\n",
    "        A list of training images and augmented images\n",
    "    aug_y:\n",
    "        A list of the inventory level for each augmented image\n",
    "    '''\n",
    "    \n",
    "    aug_methods = []\n",
    "        \n",
    "    if WITH_IMGAUG_DATA_AUG:\n",
    "        aug_methods.append(lambda x,y: _imgaug(x, y, aug_sequence))\n",
    "        \n",
    "    if WITH_OPENCV_DATA_AUG:\n",
    "        aug_methods.append(_hflip)\n",
    "        aug_methods.append(_noise)\n",
    "    \n",
    "    aug_imgs = train_imgs.copy()\n",
    "    aug_y = train_y.copy()\n",
    "        \n",
    "    for method in aug_methods:\n",
    "        imgs, y = method(train_imgs.copy(), train_y.copy())\n",
    "        aug_imgs = np.concatenate((aug_imgs, imgs))\n",
    "        aug_y = np.concatenate((aug_y, y))\n",
    "        \n",
    "    return (aug_imgs, aug_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug_imgs, train_aug_y = data_augmentation(train_imgs, train_y, aug)\n",
    "\n",
    "print(len(train_aug_imgs) / len(train_imgs), 'more images after data augmentation')\n",
    "len(train_aug_imgs), len(train_aug_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_aug_imgs[0,:,:,0], cmap='gray'); plt.show()\n",
    "plt.imshow(train_aug_imgs[-1,:,:,0], cmap='gray'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsWG3gzLTmyi"
   },
   "source": [
    "# Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: CNN\n",
    "\n",
    "input_shape = train_imgs.shape[1:]\n",
    "\n",
    "inputs = keras.Input(shape=input_shape, name='CNN_model_input')\n",
    "\n",
    "conv1 = layers.Conv2D(32, 5, strides=2, activation='relu', name='CNN_model_conv1')(inputs)\n",
    "conv2 = layers.Conv2D(32, 5, strides=2, activation='relu', name='CNN_model_conv2')(conv1)\n",
    "conv3 = layers.Conv2D(32, 3, activation='relu', name='CNN_model_conv3')(conv2)\n",
    "\n",
    "maxpool = layers.GlobalMaxPooling2D(name='CNN_model_globalmaxpool1')(conv3)\n",
    "\n",
    "dense1 = layers.Dense(32, activation='relu', name='CNN_model_dense1')(maxpool)\n",
    "dense2 = layers.Dense(32, activation='relu', name='CNN_model_dense2')(dense1)\n",
    "\n",
    "dropout = layers.Dropout(0.25, name='CNN_model_dropout1')(dense2)\n",
    "outputs = layers.Dense(1, activation='sigmoid', name='CNN_model_dense3')(dropout)\n",
    "\n",
    "model1 = keras.Model(inputs, outputs)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Transfer learning with MobileNetV2\n",
    "\n",
    "class MobileNetPreprocess(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        # mobilenet preprocess asks for data in [0, 255]\n",
    "        inputs *= 255\n",
    "\n",
    "        # mobilenet preprocess asks for data in rgb\n",
    "        inputs = tf.image.grayscale_to_rgb(inputs)\n",
    "        \n",
    "        # call mobilenet preprocess\n",
    "        inputs = keras.applications.mobilenet_v2.preprocess_input(inputs)\n",
    "        \n",
    "        return inputs\n",
    "\n",
    "inputs = keras.Input(shape=input_shape, name='Mobilenet_model_input')\n",
    "preprocess = MobileNetPreprocess(name='Mobilenet_preprocess')(inputs)\n",
    "\n",
    "# Use transfer learning and disable training on these weights\n",
    "mobilenet = keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False)\n",
    "for layer in mobilenet.layers:\n",
    "    layer.trainable = False\n",
    "mobilenet = mobilenet(preprocess)\n",
    "\n",
    "pool = layers.GlobalMaxPool2D(name='Mobilenet_model_globalmaxpool1')(mobilenet)\n",
    "dense1 = layers.Dense(32, activation='relu', name='Mobilenet_model_dense1')(pool)\n",
    "dense2 = layers.Dense(32, activation='relu', name='Mobilenet_model_dense2')(dense1)\n",
    "dropout = layers.Dropout(0.25, name='Mobilenet_model_dropout1')(dense2)\n",
    "outputs = layers.Dense(1, activation='sigmoid', name='Mobilenet_model_dense3')(dropout)\n",
    "\n",
    "model2 = keras.Model(inputs, outputs)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: Transfer learning with ResNet50\n",
    "\n",
    "class Resnet50V2Preprocess(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        # resnet preprocess asks for data in [0, 255]\n",
    "        inputs *= 255\n",
    "\n",
    "        # resnet preprocess asks for data in rgb\n",
    "        inputs = tf.image.grayscale_to_rgb(inputs)\n",
    "        \n",
    "        # call resnet preprocess\n",
    "        inputs = keras.applications.resnet_v2.preprocess_input(inputs)\n",
    "        \n",
    "        return inputs\n",
    "\n",
    "inputs = keras.Input(shape=input_shape, name='Resnet_model_input')\n",
    "preprocess = Resnet50V2Preprocess()(inputs)\n",
    "\n",
    "# Use transfer learning and disable training on these weights\n",
    "resnet = keras.applications.ResNet50V2(include_top=False)\n",
    "for layer in resnet.layers:\n",
    "    layer.trainable = False\n",
    "resnet = resnet(preprocess)\n",
    "\n",
    "pool = layers.GlobalMaxPool2D(name='Resnet_model_globalmaxpool1')(resnet)\n",
    "dense1 = layers.Dense(32, activation='relu', name='Resnet_model_dense1')(pool)\n",
    "dense2 = layers.Dense(32, activation='relu', name='Resnet_model_dense2')(dense1)\n",
    "dropout = layers.Dropout(0.25, name='Resnet_model_dropout1')(dense2)\n",
    "outputs = layers.Dense(1, activation='sigmoid', name='Resnet_model_dense3')(dropout)\n",
    "\n",
    "model3 = keras.Model(inputs, outputs)\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4: Wide-and-deep\n",
    "\n",
    "input_shape = train_imgs.shape[1:]\n",
    "\n",
    "inputs = keras.Input(shape=input_shape, name='WD_model_input')\n",
    "\n",
    "# Wide\n",
    "wide_conv = layers.Conv2D(128, 5, activation='relu', name='WD_model_wide_conv')(inputs)\n",
    "wide_pool = layers.GlobalMaxPooling2D(name='WD_model_wide_maxpool')(wide_conv)\n",
    "\n",
    "# Deep\n",
    "conv1 = layers.Conv2D(32, 5, strides=2, activation='relu', name='WD_model_conv1')(inputs)\n",
    "conv2 = layers.Conv2D(32, 5, strides=2, activation='relu', name='WD_model_conv2')(conv1)\n",
    "conv3 = layers.Conv2D(32, 3, activation='relu', name='WD_model_conv3')(conv2)\n",
    "\n",
    "maxpool = layers.GlobalMaxPooling2D(name='WD_model_globalmaxpool1')(conv3)\n",
    "\n",
    "dense1 = layers.Dense(32, activation='relu', name='WD_model_dense1')(maxpool)\n",
    "dense2 = layers.Dense(32, activation='relu', name='WD_model_dense2')(dense1)\n",
    "dropout = layers.Dropout(0.25, name='WD_model_dropout1')(dense2)\n",
    "\n",
    "concat = layers.Concatenate()([wide_pool, dropout])\n",
    "outputs = layers.Dense(1, activation='sigmoid', name='WD_model_dense3')(concat)\n",
    "\n",
    "model4 = keras.Model(inputs, outputs)\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to predict the level at 20% precision\n",
    "# so we create this custom metric \n",
    "\n",
    "def accuracy_at_20(y_true, y_pred):\n",
    "    '''Custom metric for computing accuracy at 20% precision'''\n",
    "    \n",
    "    precision = 0.2\n",
    "    \n",
    "    y_true /= precision\n",
    "    y_pred /= precision\n",
    "    \n",
    "    return keras.backend.mean(y_true == keras.backend.round(y_pred))\n",
    "\n",
    "print(accuracy_at_20(\n",
    "    tf.constant([0.2, 0.2, 0.2]),\n",
    "    tf.constant([0.2, 0.29, 0.3])\n",
    "    #            OK   OK    KO\n",
    "))\n",
    "\n",
    "accuracy_at_20(\n",
    "    tf.constant([0, 0.2, 0.4]),\n",
    "    tf.constant([0.09, 0.2, 0.49])\n",
    "    #            OK    OK   OK\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile & train on sample\n",
    "\n",
    "loss = 'mean_squared_error'\n",
    "metrics = [keras.metrics.mean_absolute_error, accuracy_at_20]\n",
    "\n",
    "models = {\n",
    "    'CNN': model1,\n",
    "    'MobileNetV2': model2,\n",
    "    'ResNet50V2': model3,\n",
    "    'Wide-and-Deep': model4\n",
    "}\n",
    "\n",
    "for model in models.values():\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=metrics)\n",
    "\n",
    "history = {}\n",
    "for name, model in models.items():\n",
    "    print('---', name, '---')\n",
    "    history[name] = model.fit(\n",
    "        np.asarray(train_aug_imgs),\n",
    "        train_aug_y,\n",
    "        epochs=100,\n",
    "        validation_data=(test_imgs, test_y)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w\n",
    "\n",
    "f, ax = plt.subplots(2,len(models), figsize=(30,10))\n",
    "colors = ['red', 'green', 'blue', 'black']\n",
    "\n",
    "ravg_w = 1\n",
    "\n",
    "for i, name in enumerate(models.keys()):\n",
    "    model_hist = history[name].history\n",
    "    \n",
    "    ax[0,i].plot(rolling_average(model_hist['mean_absolute_error'], ravg_w),\n",
    "               label=f'{name} (train)',\n",
    "               linestyle='dashed',\n",
    "               c=colors[i])\n",
    "    ax[0,i].plot(rolling_average(model_hist['val_mean_absolute_error'], ravg_w),\n",
    "               label=f'{name} (test)',\n",
    "               c=colors[i])\n",
    "    \n",
    "    ax[1,i].plot(rolling_average(model_hist['accuracy_at_20'], ravg_w),\n",
    "               label=f'{name} (train)',\n",
    "               linestyle='dashed',\n",
    "               c=colors[i])\n",
    "    ax[1,i].plot(rolling_average(model_hist['val_accuracy_at_20'], ravg_w),\n",
    "               label=f'{name} (test)',\n",
    "               c=colors[i])\n",
    "\n",
    "    ax[0,i].set_title(f'Rolling average ({ravg_w}) of the Loss')\n",
    "    ax[0,i].set_ylabel('MAE')\n",
    "    ax[0,i].set_xlabel('Epoch')\n",
    "    ax[0,i].set_ylim([0, 0.3])\n",
    "    ax[0,i].legend(loc='upper right')\n",
    "\n",
    "    ax[1,i].set_title(f'Rolling average ({ravg_w}) of the Accuracy at 20%')\n",
    "    ax[1,i].set_ylabel('Accuracy at 20%')\n",
    "    ax[1,i].set_xlabel('Epoch')\n",
    "    ax[1,i].set_ylim([0, 1])\n",
    "    ax[1,i].legend(loc='lower right')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "ravg_w = 5\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(30,10))\n",
    "for i, name in enumerate(models.keys()):\n",
    "    model_hist = history[name].history\n",
    "\n",
    "    ax[0].plot(rolling_average(model_hist['accuracy_at_20'], ravg_w),\n",
    "               label=f'{name} (train)',\n",
    "               linestyle='dashed',\n",
    "               c=colors[i])\n",
    "    \n",
    "    ax[1].plot(rolling_average(model_hist['val_accuracy_at_20'], ravg_w),\n",
    "               label=f'{name} (test)',\n",
    "               c=colors[i])\n",
    "\n",
    "    ax[0].set_title(f'Rolling average ({ravg_w}) of the train Accuracy at 20%')\n",
    "    ax[0].set_ylabel('Accuracy at 20%')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].legend(loc='lower right')\n",
    "\n",
    "    ax[1].set_title(f'Rolling average ({ravg_w}) of the test Accuracy at 20%')\n",
    "    ax[1].set_ylabel('Accuracy at 20%')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "for name, model in models.items():\n",
    "    loss, mae, acc = model.evaluate(test_imgs, test_y, verbose=0)\n",
    "    print(f'{name:>15} : MAE = {mae:.3f} - Accuracy at 20%: {acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check a test image\n",
    "nb_samples = 6\n",
    "nb_cols = 3\n",
    "\n",
    "sample_imgs, sample_y = test_imgs[:nb_samples], test_y[:nb_samples]\n",
    "sample_levels = {\n",
    "    name: model.predict(sample_imgs).flatten()\n",
    "    for name, model in models.items()\n",
    "}\n",
    "\n",
    "f, ax = plt.subplots(int(np.ceil(nb_samples / nb_cols)), \n",
    "                     nb_cols, figsize=(10,10))\n",
    "for i in range(nb_samples):\n",
    "    title = f'Ground truth: {sample_y[i]:.2f}'\n",
    "    \n",
    "    for name, scores in sample_levels.items():\n",
    "        title += f'\\n{name}: {scores[i]:.2f}'\n",
    "    \n",
    "    x, y = i // nb_cols, i % nb_cols\n",
    "    ax[x,y].set_title(title)\n",
    "    ax[x,y].imshow(sample_imgs[i,:,:,0], cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
