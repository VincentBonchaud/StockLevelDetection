{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rN6-6JavTmyM"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "217YoDxMTmyV"
   },
   "source": [
    "# Global variables definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = Path.cwd().parent\n",
    "CSV_LINK = 'https://plenty.supplies/app/dataset'\n",
    "CSV_NAME = 'squyrrel-dataset.csv'\n",
    "AUGMENTED_CSV_NAME = 'augmented_data.csv'\n",
    "\n",
    "CSV_PATH = ROOT_DIR / CSV_NAME\n",
    "BASE_IMG_DIR = ROOT_DIR / 'img'\n",
    "\n",
    "WITH_IMGAUG_DATA_AUG = True\n",
    "WITH_OPENCV_DATA_AUG = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moYHlo-WTmyY"
   },
   "source": [
    "# Download the csv metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable unverified HTTPS warnings\n",
    "import urllib3\n",
    "urllib3.disable_warnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CSV_PATH.is_file():\n",
    "    raw_csv = requests.get(CSV_LINK, verify=False).content\n",
    "    CSV_PATH.write_bytes(raw_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLzlE_lxTmya"
   },
   "source": [
    "# Download the images with inventory level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_base_images(csv_path, output_dir):\n",
    "    prefix_url = 'https://plenty.lyreco.com'\n",
    "    \n",
    "    df = pd.read_csv(csv_path, sep=';', index_col=0).dropna()\n",
    "    \n",
    "    for (label_id, inv_level, img_url) in df.itertuples():\n",
    "        full_url = prefix_url + img_url\n",
    "        output_file = output_dir / f'{label_id}_{inv_level}.png'\n",
    "        \n",
    "        img_data = requests.get(full_url, verify=False).content\n",
    "        output_file.write_bytes(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not BASE_IMG_DIR.is_dir():\n",
    "    BASE_IMG_DIR.mkdir()\n",
    "    download_base_images(CSV_PATH, BASE_IMG_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYqg7qOGTmyd"
   },
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_files = list(BASE_IMG_DIR.glob('*'))\n",
    "len(dataset_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files, test_files = train_test_split(dataset_files, test_size=0.2, random_state=42)\n",
    "len(train_files), len(test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlxDMOAHTmyf"
   },
   "source": [
    "# Load training files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the gray image and normalize it\n",
    "\n",
    "def pad_resize(img, h, w):\n",
    "    ratio_h = h / img.shape[0]\n",
    "    ratio_w = w / img.shape[1]\n",
    "    \n",
    "    # Resize while keeping same ratio\n",
    "    ratio = min(ratio_h, ratio_w)\n",
    "    img = cv2.resize(img, (0, 0), fx=ratio, fy=ratio, interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # Pad the rest of the image\n",
    "    pad_y, pad_x = h - img.shape[0], w - img.shape[1]\n",
    "    img = cv2.copyMakeBorder(\n",
    "        img,\n",
    "        top = pad_y // 2,\n",
    "        bottom = (pad_y + 1) // 2,\n",
    "        left = pad_x // 2,\n",
    "        right = (pad_x + 1) // 2,\n",
    "        borderType = cv2.BORDER_CONSTANT,\n",
    "        value = [255, 255, 255]\n",
    "    )\n",
    "    \n",
    "    return img\n",
    "\n",
    "def load_gray(file_paths, reshape_h, reshape_w):\n",
    "    # Load the gray images & normalize\n",
    "    imgs = [cv2.imread(str(f), cv2.IMREAD_GRAYSCALE).astype(np.float32) for f in file_paths]\n",
    "    \n",
    "    # Resize the images\n",
    "    imgs = np.asarray([pad_resize(img, reshape_h, reshape_w) for img in imgs])\n",
    "    \n",
    "    imgs = imgs[..., None] / 255\n",
    "\n",
    "    return imgs\n",
    "\n",
    "reshape_h, reshape_w = 224, 224\n",
    "train_imgs = load_gray(train_files, reshape_h, reshape_w)\n",
    "test_imgs = load_gray(test_files, reshape_h, reshape_w)\n",
    "\n",
    "plt.imshow(train_imgs[0,:,:,0], cmap='gray'); plt.show()\n",
    "plt.imshow(train_imgs[-1,:,:,0], cmap='gray'); plt.show()\n",
    "\n",
    "train_imgs.shape, test_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the inventory level from the filenames\n",
    "\n",
    "def extract_inv_level(file_paths):\n",
    "    # Remove file extension & Keep only the inventory level\n",
    "    levels_str = [f.stem.split('_')[-1] for f in file_paths]\n",
    "    \n",
    "    # Convert to float\n",
    "    return np.array(levels_str, dtype=np.float32)\n",
    "\n",
    "train_y, test_y = extract_inv_level(train_files), extract_inv_level(test_files)\n",
    "train_y[:5], test_y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MY2c6ZZxTmyh"
   },
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.util import random_noise\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.seed(42)\n",
    "\n",
    "# Define the augmentation to apply\n",
    "aug = iaa.Sequential([\n",
    "    iaa.Fliplr(0.7), # horizontal flips\n",
    "        \n",
    "    # Small gaussian blur with random sigma between 0 and 0.5.\n",
    "    iaa.Sometimes(0.5, iaa.GaussianBlur(sigma=(0, 0.5))),\n",
    "    \n",
    "    # Strengthen or weaken the contrast in each image.\n",
    "    iaa.LinearContrast((0.75, 1.5)),\n",
    "    \n",
    "    # Make some images brighter and some darker.\n",
    "    iaa.Multiply((0.7, 1.3), per_channel=0.2),\n",
    "    \n",
    "    # Scale/zoom them, translate/move them, rotate them and shear them.\n",
    "    iaa.Affine(\n",
    "        scale={\"x\": (1, 1.1), \"y\": (1, 1.1)},\n",
    "    )\n",
    "], random_order=True) # apply augmenters in random order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def brightness(img, low, high):\n",
    "#     value = random.uniform(low, high)\n",
    "#     hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "#     hsv = np.array(hsv, dtype = np.float64)\n",
    "#     hsv[:,:,1] = hsv[:,:,1]*value\n",
    "#     hsv[:,:,1][hsv[:,:,1]>255]  = 255\n",
    "#     hsv[:,:,2] = hsv[:,:,2]*value \n",
    "#     hsv[:,:,2][hsv[:,:,2]>255]  = 255\n",
    "#     hsv = np.array(hsv, dtype = np.uint8)\n",
    "#     img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "#     return img\n",
    "\n",
    "# Brightness\n",
    "# brighter_image = brightness(gray_image, 0.4, 3)\n",
    "# less_bright_image = brightness(gray_image, 0.4, 10)\n",
    "\n",
    "def _hflip(imgs, y):\n",
    "    return (np.reshape([cv2.flip(img, 1) for img in imgs], imgs.shape), y)\n",
    "\n",
    "def _noise(imgs, y):\n",
    "    return (np.reshape([random_noise(img, mode='s&p', amount=0.061) for img in imgs], imgs.shape), y)\n",
    "\n",
    "def _imgaug(imgs, y, aug_sequence, nb_aug=3):\n",
    "    augmented_images = []\n",
    "    augmented_y = []\n",
    "    \n",
    "    for i in range(len(imgs)):\n",
    "        duplicated_imgs = np.array([imgs[i] for _ in range(nb_aug)])\n",
    "        augmented_images += list(aug_sequence(images=duplicated_imgs))\n",
    "        augmented_y += [y[i]] * nb_aug\n",
    "        \n",
    "    return np.array(augmented_images), np.array(augmented_y)\n",
    "\n",
    "\n",
    "def data_augmentation(train_imgs, train_y, aug_sequence):\n",
    "    '''\n",
    "    Augment training data by applying tranformations on it.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    train_imgs:\n",
    "        A list of the training images data\n",
    "    train_y:\n",
    "        A list of the inventory level for each training image\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    aug_imgs:\n",
    "        A list of training images and augmented images\n",
    "    aug_y:\n",
    "        A list of the inventory level for each augmented image\n",
    "    '''\n",
    "    \n",
    "    aug_methods = []\n",
    "        \n",
    "    if WITH_IMGAUG_DATA_AUG:\n",
    "        aug_methods.append(lambda x,y: _imgaug(x, y, aug_sequence))\n",
    "        \n",
    "    if WITH_OPENCV_DATA_AUG:\n",
    "        aug_methods.append(_hflip)\n",
    "        aug_methods.append(_noise)\n",
    "    \n",
    "    aug_imgs = train_imgs.copy()\n",
    "    aug_y = train_y.copy()\n",
    "        \n",
    "    for method in aug_methods:\n",
    "        imgs, y = method(train_imgs.copy(), train_y.copy())\n",
    "        aug_imgs = np.concatenate((aug_imgs, imgs))\n",
    "        aug_y = np.concatenate((aug_y, y))\n",
    "        \n",
    "    return (aug_imgs, aug_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug_imgs, train_aug_y = data_augmentation(train_imgs, train_y, aug)\n",
    "\n",
    "print(len(train_aug_imgs) / len(train_imgs), 'more images after data augmentation')\n",
    "len(train_aug_imgs), len(train_aug_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_aug_imgs[0,:,:,0], cmap='gray'); plt.show()\n",
    "plt.imshow(train_aug_imgs[-1,:,:,0], cmap='gray'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsWG3gzLTmyi"
   },
   "source": [
    "# Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: CNN\n",
    "\n",
    "input_shape = train_imgs.shape[1:]\n",
    "\n",
    "inputs = keras.Input(shape=input_shape, name='CNN_model_input')\n",
    "\n",
    "conv1 = layers.Conv2D(32, 5, strides=2, activation='relu', name='CNN_model_conv1')(inputs)\n",
    "conv2 = layers.Conv2D(32, 5, strides=2, activation='relu', name='CNN_model_conv2')(conv1)\n",
    "conv3 = layers.Conv2D(32, 3, activation='relu', name='CNN_model_conv3')(conv2)\n",
    "\n",
    "maxpool = layers.GlobalMaxPooling2D(name='CNN_model_globalmaxpool1')(conv3)\n",
    "\n",
    "dense1 = layers.Dense(32, activation='relu', name='CNN_model_dense1')(maxpool)\n",
    "dense2 = layers.Dense(32, activation='relu', name='CNN_model_dense2')(dense1)\n",
    "\n",
    "dropout = layers.Dropout(0.25, name='CNN_model_dropout1')(dense2)\n",
    "outputs = layers.Dense(1, activation='sigmoid', name='CNN_model_dense3')(dropout)\n",
    "\n",
    "model1 = keras.Model(inputs, outputs)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Transfer learning with MobileNetV2\n",
    "\n",
    "class MobileNetPreprocess(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        # mobilenet preprocess asks for data in [0, 255]\n",
    "        inputs *= 255\n",
    "\n",
    "        # mobilenet preprocess asks for data in rgb\n",
    "        inputs = tf.image.grayscale_to_rgb(inputs)\n",
    "        \n",
    "        # call mobilenet preprocess\n",
    "        inputs = keras.applications.mobilenet_v2.preprocess_input(inputs)\n",
    "        \n",
    "        return inputs\n",
    "\n",
    "inputs = keras.Input(shape=input_shape, name='Mobilenet_model_input')\n",
    "preprocess = MobileNetPreprocess(name='Mobilenet_preprocess')(inputs)\n",
    "\n",
    "# Use transfer learning and disable training on these weights\n",
    "mobilenet = keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False)\n",
    "for layer in mobilenet.layers:\n",
    "    layer.trainable = False\n",
    "mobilenet = mobilenet(preprocess)\n",
    "\n",
    "pool = layers.GlobalMaxPool2D(name='Mobilenet_model_globalmaxpool1')(mobilenet)\n",
    "dense1 = layers.Dense(32, activation='relu', name='Mobilenet_model_dense1')(pool)\n",
    "dense2 = layers.Dense(32, activation='relu', name='Mobilenet_model_dense2')(dense1)\n",
    "dropout = layers.Dropout(0.25, name='Mobilenet_model_dropout1')(dense2)\n",
    "outputs = layers.Dense(1, activation='sigmoid', name='Mobilenet_model_dense3')(dropout)\n",
    "\n",
    "model2 = keras.Model(inputs, outputs)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: Transfer learning with ResNet50\n",
    "\n",
    "class Resnet50V2Preprocess(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        # resnet preprocess asks for data in [0, 255]\n",
    "        inputs *= 255\n",
    "\n",
    "        # resnet preprocess asks for data in rgb\n",
    "        inputs = tf.image.grayscale_to_rgb(inputs)\n",
    "        \n",
    "        # call resnet preprocess\n",
    "        inputs = keras.applications.resnet_v2.preprocess_input(inputs)\n",
    "        \n",
    "        return inputs\n",
    "\n",
    "inputs = keras.Input(shape=input_shape, name='Resnet_model_input')\n",
    "preprocess = Resnet50V2Preprocess()(inputs)\n",
    "\n",
    "# Use transfer learning and disable training on these weights\n",
    "resnet = keras.applications.ResNet50V2(include_top=False)\n",
    "for layer in resnet.layers:\n",
    "    layer.trainable = False\n",
    "resnet = resnet(preprocess)\n",
    "\n",
    "pool = layers.GlobalMaxPool2D(name='Resnet_model_globalmaxpool1')(resnet)\n",
    "dense1 = layers.Dense(32, activation='relu', name='Resnet_model_dense1')(pool)\n",
    "dense2 = layers.Dense(32, activation='relu', name='Resnet_model_dense2')(dense1)\n",
    "dropout = layers.Dropout(0.25, name='Resnet_model_dropout1')(dense2)\n",
    "outputs = layers.Dense(1, activation='sigmoid', name='Resnet_model_dense3')(dropout)\n",
    "\n",
    "model3 = keras.Model(inputs, outputs)\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4: Wide-and-deep\n",
    "\n",
    "input_shape = train_imgs.shape[1:]\n",
    "\n",
    "inputs = keras.Input(shape=input_shape, name='WD_model_input')\n",
    "\n",
    "# Wide\n",
    "wide_conv = layers.Conv2D(128, 5, activation='relu', name='WD_model_wide_conv')(inputs)\n",
    "wide_pool = layers.GlobalMaxPooling2D(name='WD_model_wide_maxpool')(wide_conv)\n",
    "\n",
    "# Deep\n",
    "conv1 = layers.Conv2D(32, 5, strides=2, activation='relu', name='WD_model_conv1')(inputs)\n",
    "conv2 = layers.Conv2D(32, 5, strides=2, activation='relu', name='WD_model_conv2')(conv1)\n",
    "conv3 = layers.Conv2D(32, 3, activation='relu', name='WD_model_conv3')(conv2)\n",
    "\n",
    "maxpool = layers.GlobalMaxPooling2D(name='WD_model_globalmaxpool1')(conv3)\n",
    "\n",
    "dense1 = layers.Dense(32, activation='relu', name='WD_model_dense1')(maxpool)\n",
    "dense2 = layers.Dense(32, activation='relu', name='WD_model_dense2')(dense1)\n",
    "dropout = layers.Dropout(0.25, name='WD_model_dropout1')(dense2)\n",
    "\n",
    "concat = layers.Concatenate()([wide_pool, dropout])\n",
    "outputs = layers.Dense(1, activation='sigmoid', name='WD_model_dense3')(concat)\n",
    "\n",
    "model4 = keras.Model(inputs, outputs)\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to predict the level at 20% precision\n",
    "# so we create this custom metric \n",
    "\n",
    "def accuracy_at_20(y_true, y_pred):\n",
    "    '''Custom metric for computing accuracy at 20% precision'''\n",
    "    \n",
    "    precision = 0.2\n",
    "    \n",
    "    y_true /= precision\n",
    "    y_pred /= precision\n",
    "    \n",
    "    return keras.backend.mean(y_true == keras.backend.round(y_pred))\n",
    "\n",
    "print(accuracy_at_20(\n",
    "    tf.constant([0.2, 0.2, 0.2]),\n",
    "    tf.constant([0.2, 0.29, 0.3])\n",
    "    #            OK   OK    KO\n",
    "))\n",
    "\n",
    "accuracy_at_20(\n",
    "    tf.constant([0, 0.2, 0.4]),\n",
    "    tf.constant([0.09, 0.2, 0.49])\n",
    "    #            OK    OK   OK\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile & train on sample\n",
    "\n",
    "loss = 'mean_squared_error'\n",
    "metrics = [keras.metrics.mean_absolute_error, accuracy_at_20]\n",
    "\n",
    "models = {\n",
    "    'CNN': model1,\n",
    "    'MobileNetV2': model2,\n",
    "    'ResNet50V2': model3,\n",
    "    'Wide-and-Deep': model4\n",
    "}\n",
    "\n",
    "for model in models.values():\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=metrics)\n",
    "\n",
    "history = {}\n",
    "for name, model in models.items():\n",
    "    print('---', name, '---')\n",
    "    history[name] = model.fit(\n",
    "        np.asarray(train_aug_imgs),\n",
    "        train_aug_y,\n",
    "        epochs=100,\n",
    "        validation_data=(test_imgs, test_y)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w\n",
    "\n",
    "f, ax = plt.subplots(2,len(models), figsize=(30,10))\n",
    "colors = ['red', 'green', 'blue', 'black']\n",
    "\n",
    "ravg_w = 1\n",
    "\n",
    "for i, name in enumerate(models.keys()):\n",
    "    model_hist = history[name].history\n",
    "    \n",
    "    ax[0,i].plot(rolling_average(model_hist['mean_absolute_error'], ravg_w),\n",
    "               label=f'{name} (train)',\n",
    "               linestyle='dashed',\n",
    "               c=colors[i])\n",
    "    ax[0,i].plot(rolling_average(model_hist['val_mean_absolute_error'], ravg_w),\n",
    "               label=f'{name} (test)',\n",
    "               c=colors[i])\n",
    "    \n",
    "    ax[1,i].plot(rolling_average(model_hist['accuracy_at_20'], ravg_w),\n",
    "               label=f'{name} (train)',\n",
    "               linestyle='dashed',\n",
    "               c=colors[i])\n",
    "    ax[1,i].plot(rolling_average(model_hist['val_accuracy_at_20'], ravg_w),\n",
    "               label=f'{name} (test)',\n",
    "               c=colors[i])\n",
    "\n",
    "    ax[0,i].set_title(f'Rolling average ({ravg_w}) of the Loss')\n",
    "    ax[0,i].set_ylabel('MAE')\n",
    "    ax[0,i].set_xlabel('Epoch')\n",
    "    ax[0,i].set_ylim([0, 0.3])\n",
    "    ax[0,i].legend(loc='upper right')\n",
    "\n",
    "    ax[1,i].set_title(f'Rolling average ({ravg_w}) of the Accuracy at 20%')\n",
    "    ax[1,i].set_ylabel('Accuracy at 20%')\n",
    "    ax[1,i].set_xlabel('Epoch')\n",
    "    ax[1,i].set_ylim([0, 1])\n",
    "    ax[1,i].legend(loc='lower right')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "ravg_w = 5\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(30,10))\n",
    "for i, name in enumerate(models.keys()):\n",
    "    model_hist = history[name].history\n",
    "\n",
    "    ax[0].plot(rolling_average(model_hist['accuracy_at_20'], ravg_w),\n",
    "               label=f'{name} (train)',\n",
    "               linestyle='dashed',\n",
    "               c=colors[i])\n",
    "    \n",
    "    ax[1].plot(rolling_average(model_hist['val_accuracy_at_20'], ravg_w),\n",
    "               label=f'{name} (test)',\n",
    "               c=colors[i])\n",
    "\n",
    "    ax[0].set_title(f'Rolling average ({ravg_w}) of the train Accuracy at 20%')\n",
    "    ax[0].set_ylabel('Accuracy at 20%')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].legend(loc='lower right')\n",
    "\n",
    "    ax[1].set_title(f'Rolling average ({ravg_w}) of the test Accuracy at 20%')\n",
    "    ax[1].set_ylabel('Accuracy at 20%')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "for name, model in models.items():\n",
    "    loss, mae, acc = model.evaluate(test_imgs, test_y, verbose=0)\n",
    "    print(f'{name:>15} : MAE = {mae:.3f} - Accuracy at 20%: {acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check a test image\n",
    "nb_samples = 6\n",
    "nb_cols = 3\n",
    "\n",
    "sample_imgs, sample_y = test_imgs[:nb_samples], test_y[:nb_samples]\n",
    "sample_levels = {\n",
    "    name: model.predict(sample_imgs).flatten()\n",
    "    for name, model in models.items()\n",
    "}\n",
    "\n",
    "f, ax = plt.subplots(int(np.ceil(nb_samples / nb_cols)), \n",
    "                     nb_cols, figsize=(10,10))\n",
    "for i in range(nb_samples):\n",
    "    title = f'Ground truth: {sample_y[i]:.2f}'\n",
    "    \n",
    "    for name, scores in sample_levels.items():\n",
    "        title += f'\\n{name}: {scores[i]:.2f}'\n",
    "    \n",
    "    x, y = i // nb_cols, i % nb_cols\n",
    "    ax[x,y].set_title(title)\n",
    "    ax[x,y].imshow(sample_imgs[i,:,:,0], cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
